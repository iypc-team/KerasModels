{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae67b673",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 12/12/2021-1\n",
    "# https://www.tensorflow.org/hub/tutorials/tf2_image_retraining\n",
    "from __future__ import absolute_import\n",
    "from IPython.display import clear_output\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "from os.path import exists, join\n",
    "\n",
    "contentPath = os.getcwd()\n",
    "cv2Path=join(contentPath, 'CV2Images')\n",
    "testPath=join(contentPath, 'images')\n",
    "checkpointPath = join(contentPath, 'ChkPoints')\n",
    "if not exists(checkpointPath):\n",
    "    os.makedirs(checkpointPath)\n",
    "\n",
    "import itertools\n",
    "import glob, os, time\n",
    "from time import sleep\n",
    "\n",
    "import matplotlib.pylab as plt\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "\n",
    "for fil in glob.glob('*.h5'):\n",
    "    os.remove(fil)\n",
    "\n",
    "print(\"TF version:\", tf.__version__)\n",
    "print(\"Hub version:\", hub.__version__)\n",
    "print(\"GPU is\", \"available\" if tf.config.list_physical_devices('GPU') else \"NOT AVAILABLE\")\n",
    "print('cwd: ', os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c0a9c61",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing import image_dataset_from_directory\n",
    "test_ds = image_dataset_from_directory(\n",
    "    testPath,\n",
    "    color_mode='rgb',\n",
    "    image_size=(224, 224),\n",
    "    batch_size=1)\n",
    "print()\n",
    "# clear_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f394f6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"mobilenet_v2_100_224\" # @param ['mobilenet_v2_100_224', 'mobilenet_v2_130_224', 'mobilenet_v2_140_224', 'mobilenet_v3_small_100_224', 'mobilenet_v3_small_075_224', 'mobilenet_v3_large_100_224', 'mobilenet_v3_large_075_224']\n",
    "\n",
    "model_handle_map = {\n",
    "  \"mobilenet_v2_100_224\": \"https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4\",\n",
    "  \"mobilenet_v2_130_224\": \"https://tfhub.dev/google/imagenet/mobilenet_v2_130_224/feature_vector/4\",\n",
    "  \"mobilenet_v2_140_224\": \"https://tfhub.dev/google/imagenet/mobilenet_v2_140_224/feature_vector/4\",\n",
    "  \"mobilenet_v3_small_100_224\": \"https://tfhub.dev/google/imagenet/mobilenet_v3_small_100_224/feature_vector/5\",\n",
    "  \"mobilenet_v3_small_075_224\": \"https://tfhub.dev/google/imagenet/mobilenet_v3_small_075_224/feature_vector/5\",\n",
    "  \"mobilenet_v3_large_100_224\": \"https://tfhub.dev/google/imagenet/mobilenet_v3_large_100_224/feature_vector/5\",\n",
    "  \"mobilenet_v3_large_075_224\": \"https://tfhub.dev/google/imagenet/mobilenet_v3_large_075_224/feature_vector/5\",\n",
    "}\n",
    "\n",
    "model_image_size_map = {}\n",
    "\n",
    "model_handle = model_handle_map.get(model_name)\n",
    "pixels = model_image_size_map.get(model_name, 224)\n",
    "\n",
    "print(f\"Selected model: {model_name} : {model_handle}\")\n",
    "\n",
    "IMAGE_SIZE = (pixels, pixels)\n",
    "print(f\"Input size {IMAGE_SIZE}\")\n",
    "\n",
    "BATCH_SIZE = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d299dd74",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_dataset(subset):\n",
    "    return tf.keras.preprocessing.image_dataset_from_directory(\n",
    "        cv2Path,\n",
    "        validation_split=.20,\n",
    "        subset=subset,\n",
    "        label_mode=\"categorical\",\n",
    "        # Seed needs to provided when using validation_split and shuffle = True.\n",
    "        seed=456,\n",
    "        image_size=IMAGE_SIZE,\n",
    "        batch_size=BATCH_SIZE)\n",
    "\n",
    "train_ds = build_dataset(\"training\")\n",
    "class_names = tuple(train_ds.class_names)\n",
    "train_size = train_ds.cardinality().numpy()\n",
    "train_ds = train_ds.unbatch().batch(BATCH_SIZE)\n",
    "train_ds = train_ds.repeat()\n",
    "\n",
    "normalization_layer = tf.keras.layers.Rescaling(1. / 255)\n",
    "preprocessing_model = tf.keras.Sequential([normalization_layer])\n",
    "\n",
    "do_data_augmentation = True\n",
    "if do_data_augmentation:\n",
    "    preprocessing_model.add(tf.keras.layers.RandomRotation(40))\n",
    "    preprocessing_model.add(\n",
    "        tf.keras.layers.RandomTranslation(0, 0.2))\n",
    "    preprocessing_model.add(\n",
    "        tf.keras.layers.RandomTranslation(0.2, 0))\n",
    "    # Like the old tf.keras.preprocessing.image.ImageDataGenerator(),\n",
    "    # image sizes are fixed when reading, and then a random zoom is applied.\n",
    "    # If all training inputs are larger than image_size, one could also use\n",
    "    # RandomCrop with a batch size of 1 and rebatch later.\n",
    "    preprocessing_model.add(tf.keras.layers.RandomZoom(-0.1, -0.1))\n",
    "    preprocessing_model.add(\n",
    "        tf.keras.layers.RandomFlip(mode=\"horizontal\"))\n",
    "    \n",
    "train_ds = train_ds.map(lambda images, labels:\n",
    "                        (preprocessing_model(images), labels))\n",
    "print()\n",
    "val_ds = build_dataset(\"validation\")\n",
    "valid_size = val_ds.cardinality().numpy()\n",
    "val_ds = val_ds.unbatch().batch(BATCH_SIZE)\n",
    "val_ds = val_ds.map(lambda images, labels:\n",
    "                    (normalization_layer(images), labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83189d0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "do_fine_tuning = True\n",
    "\n",
    "print(\"Building model with\", model_handle)\n",
    "model = tf.keras.Sequential([\n",
    "    # Explicitly define the input shape so the model can be properly\n",
    "    # loaded by the TFLiteConverter\n",
    "    tf.keras.layers.InputLayer(input_shape=IMAGE_SIZE + (3,)),\n",
    "    hub.KerasLayer(model_handle, trainable=do_fine_tuning),\n",
    "    tf.keras.layers.Dropout(rate=0.2),\n",
    "    tf.keras.layers.Dense(len(class_names),\n",
    "                          kernel_regularizer=tf.keras.regularizers.l2(0.0001))\n",
    "])\n",
    "model.build((None,)+IMAGE_SIZE+(3,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0b88554",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db4f8d8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "  optimizer=tf.keras.optimizers.SGD(learning_rate=0.005,\n",
    "                                    momentum=0.9), \n",
    "  loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True,\n",
    "                                               label_smoothing=0.1),\n",
    "  metrics=['accuracy'])\n",
    "print(model.built)\n",
    "sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bbce9ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "earlyStop = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='loss', min_delta=0, patience=1, verbose=1,\n",
    "    mode='auto', baseline=None, restore_best_weights=False\n",
    ")\n",
    "\n",
    "checkpoints = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath = checkpointPath,\n",
    "    monitor='loss', verbose=1, save_best_only=True,\n",
    "    save_weights_only=False, mode='auto', save_freq='epoch',\n",
    "    options=None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08818ac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "steps_per_epoch = train_size // BATCH_SIZE\n",
    "validation_steps = valid_size // BATCH_SIZE\n",
    "hist = model.fit(\n",
    "    train_ds, validation_data=val_ds,\n",
    "    epochs=10, steps_per_epoch=steps_per_epoch,\n",
    "    callbacks=[earlyStop, checkpoints],\n",
    "    validation_steps=validation_steps).history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6314e69b",
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.keras.utils.custom_object_scope(custom_objects):\n",
    "    new_model = keras.models.clone_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b026103",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelName = model_name + '_retrained.h5'\n",
    "modelSavePath = join(contentPath, modelName)\n",
    "# serialize model to JSON\n",
    "model_json = model.to_json()\n",
    "\n",
    "with open(\"model.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "    # print(json_file)\n",
    "\n",
    "# serialize weights to HDF5\n",
    "# model.save(\"model.h5\")\n",
    "model.save(modelSavePath)\n",
    "\n",
    "print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb15da0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([tf.keras.Input((32,)), tf.keras.layers.Dense(1)]\n",
    ")\n",
    "config = model.get_config()\n",
    "new_model = tf.keras.Sequential.from_config(config)\n",
    "new_model.predict_on_batch(test_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de013a5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelName = model_name + '_retrained.h5'\n",
    "modelSavePath = join(contentPath, modelName)\n",
    "model.save(modelName, overwrite=True)\n",
    "modelSavePath"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
