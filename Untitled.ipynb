{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a591472d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF version:  \u001b[1;94m2.7.0\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# 11/27/2021-1\n",
    "# https://www.tensorflow.org/hub/tutorials/tf2_image_retraining\n",
    "from __future__ import absolute_import, division\n",
    "from IPython.display import clear_output\n",
    "from BashColors import C\n",
    "\n",
    "# import itertools\n",
    "import glob, os\n",
    "from os.path import abspath, exists, join\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2' \n",
    "\n",
    "\n",
    "import matplotlib.pylab as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "contentPath=os.getcwd()\n",
    "cv2Path=join(contentPath, 'CV2Images')\n",
    "testPath=join(contentPath, 'images')\n",
    "\n",
    "print(f\"TF version:  {C.BIBlue}{tf.__version__}{C.ColorOff}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "18158986",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelGlobList=glob.glob('my_model.h5', recursive=True)\n",
    "for pth in sorted(modelGlobList):\n",
    "    fullPath=abspath(pth)\n",
    "    print(fullPath)\n",
    "    os.remove(fullPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c5d05902",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 216 files belonging to 2 classes.\n",
      "Using 173 files for training.\n",
      "\n",
      "Found 216 files belonging to 2 classes.\n",
      "Using 43 files for validation.\n",
      "\n",
      "Found 4 files belonging to 1 classes.\n"
     ]
    }
   ],
   "source": [
    "IMAGE_SIZE=(224, 224)\n",
    "BATCH_SIZE = 4\n",
    "\n",
    "import tensorflow\n",
    "from tensorflow.keras.utils import image_dataset_from_directory\n",
    "train_ds = image_dataset_from_directory(\n",
    "    cv2Path,\n",
    "    color_mode='rgb',\n",
    "    validation_split=0.2,\n",
    "    subset=\"training\",\n",
    "    seed=456,\n",
    "    image_size=(224, 224),\n",
    "    batch_size=BATCH_SIZE)\n",
    "print()\n",
    "\n",
    "validation_ds = image_dataset_from_directory(\n",
    "    cv2Path,\n",
    "    color_mode='rgb',\n",
    "    validation_split=0.2,\n",
    "    subset=\"validation\",\n",
    "    seed=456,\n",
    "    image_size=(224, 224),\n",
    "    batch_size=BATCH_SIZE)\n",
    "print()\n",
    "\n",
    "test_ds = image_dataset_from_directory(\n",
    "    testPath,\n",
    "    color_mode='rgb',\n",
    "    image_size=(224, 224),\n",
    "    batch_size = BATCH_SIZE)\n",
    "# clear_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a7a1293e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class_names = tuple(test_ds.class_names)\n",
    "train_size = test_ds.cardinality().numpy()\n",
    "test_ds = test_ds.unbatch().batch(BATCH_SIZE)\n",
    "test_ds = test_ds.repeat()\n",
    "\n",
    "normalization_layer = tf.keras.layers.Rescaling(1. / 255)\n",
    "preprocessing_model = tf.keras.Sequential([normalization_layer])\n",
    "\n",
    "do_data_augmentation = True\n",
    "\n",
    "if do_data_augmentation:\n",
    "    preprocessing_model.add(tf.keras.layers.RandomRotation(20))\n",
    "    preprocessing_model.add(\n",
    "        tf.keras.layers.RandomTranslation(0, 0.2))\n",
    "    preprocessing_model.add(\n",
    "        tf.keras.layers.RandomTranslation(0.2, 0))\n",
    "    # Like the old tf.keras.preprocessing.image.ImageDataGenerator(),\n",
    "    # image sizes are fixed when reading, and then a random zoom is applied.\n",
    "    # If all training inputs are larger than image_size, one could also use\n",
    "    # RandomCrop with a batch size of 1 and rebatch later.\n",
    "    preprocessing_model.add(tf.keras.layers.RandomZoom(-0.1, 0.1))\n",
    "    preprocessing_model.add(\n",
    "        tf.keras.layers.RandomFlip(mode=\"horizontal\"))\n",
    "    \n",
    "test_ds = test_ds.map(lambda images, labels:\n",
    "                        (preprocessing_model(images), labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f0286273",
   "metadata": {},
   "outputs": [],
   "source": [
    "# val_ds = build_dataset(\"validation\")\n",
    "valid_size = validation_ds.cardinality().numpy()\n",
    "val_ds = validation_ds.unbatch().batch(BATCH_SIZE)\n",
    "val_ds = validation_ds.map(lambda images, labels:\n",
    "                    (normalization_layer(images), labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "81b1df38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_6 (Conv2D)           (None, 222, 222, 32)      896       \n",
      "                                                                 \n",
      " max_pooling2d_4 (MaxPooling  (None, 111, 111, 32)     0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_7 (Conv2D)           (None, 109, 109, 64)      18496     \n",
      "                                                                 \n",
      " max_pooling2d_5 (MaxPooling  (None, 54, 54, 64)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_8 (Conv2D)           (None, 52, 52, 64)        36928     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 56,320\n",
      "Trainable params: 56,320\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "You must compile your model before training/testing. Use `model.compile(optimizer, loss)`.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_2088/2197487588.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0mtest_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0mtest_target\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m \u001b[0mthisHistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_target\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;31m# Calling `save('my_model')` creates a SavedModel folder `my_model`.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/srv/conda/envs/notebook/lib/python3.7/site-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/srv/conda/envs/notebook/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_assert_compile_was_called\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2860\u001b[0m     \u001b[0;31m# (i.e. whether the model is built and its inputs/outputs are set).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2861\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_compiled\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2862\u001b[0;31m       raise RuntimeError('You must compile your model before '\n\u001b[0m\u001b[1;32m   2863\u001b[0m                          \u001b[0;34m'training/testing. '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2864\u001b[0m                          'Use `model.compile(optimizer, loss)`.')\n",
      "\u001b[0;31mRuntimeError\u001b[0m: You must compile your model before training/testing. Use `model.compile(optimizer, loss)`."
     ]
    }
   ],
   "source": [
    "from tensorflow.keras import layers\n",
    "def get_model():\n",
    "    '''\n",
    "    # Create a simple model.\n",
    "    inputs = tf.keras.Input(shape=(32,))\n",
    "    outputs = tf.keras.layers.Dense(1)(inputs)\n",
    "    model = tf.keras.Model(inputs, outputs)\n",
    "    model.compile(optimizer=\"adam\", loss=\"mean_squared_error\")\n",
    "    '''\n",
    "    model = tf.keras.models.Sequential()\n",
    "    model.add(layers.Conv2D(32, (3, 3), activation='relu',\n",
    "                            input_shape=(224, 224, 3)))\n",
    "    model.add(layers.MaxPooling2D((2, 2)))\n",
    "    model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "    model.add(layers.MaxPooling2D((2, 2)))\n",
    "    model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "    return model\n",
    "\n",
    "\n",
    "model = get_model()\n",
    "print(model.summary())\n",
    "# Train the model.\n",
    "test_input = np.random.random((128, 32))\n",
    "test_target = np.random.random((128, 1))\n",
    "thisHistory = model.fit(test_input, test_target)\n",
    "\n",
    "# Calling `save('my_model')` creates a SavedModel folder `my_model`.\n",
    "model.save(\"my_model.h5\", overwrite=True)\n",
    "\n",
    "# It can be used to reconstruct the model identically.\n",
    "newModel = tf.keras.models.load_model(\"my_model.h5\")\n",
    "\n",
    "# Let's check:\n",
    "np.testing.assert_allclose(\n",
    "    model.predict(test_input), newModel.predict(test_input)\n",
    ")\n",
    "\n",
    "# The reconstructed model is already compiled and has retained the optimizer\n",
    "# state, so training can resume:\n",
    "newModel.fit(test_input, test_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "966c5d85",
   "metadata": {},
   "outputs": [],
   "source": [
    "thisHistory.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dc38e48",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self, a):\n",
    "        self.var = tf.Variable(a, name=\"var_a\")\n",
    "\n",
    "    def call(self, inputs, training=False):\n",
    "        if training:\n",
    "            return inputs * self.var\n",
    "        else:\n",
    "            return inputs\n",
    "\n",
    "    def get_config(self):\n",
    "        return {\"a\": self.var.numpy()}\n",
    "\n",
    "    # There's actually no need to define `from_config` here, since returning\n",
    "    # `cls(**config)` is the default behavior.\n",
    "    @classmethod\n",
    "    def from_config(cls, config):\n",
    "        return cls(**config)\n",
    "\n",
    "\n",
    "layer = CustomLayer(5)\n",
    "layer.var.assign(2)\n",
    "\n",
    "serialized_layer = tf.keras.layers.serialize(layer)\n",
    "new_layer = tf.keras.layers.deserialize(\n",
    "    serialized_layer, custom_objects={\"CustomLayer\": CustomLayer}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8a7503b",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Registering the custom object\n",
    "Keras keeps a note of which class generated the config. From the example above, tf.keras.layers.serialize generates a serialized form of the custom layer:\n",
    "'''\n",
    "{'class_name': 'CustomLayer', 'config': {'a': 2} }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "681441eb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
